{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train_df, test_df):    \n",
    "    idx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "    var_info_df = pd.DataFrame(index = idx)\n",
    "    means = []\n",
    "    stds = []\n",
    "    kurts = []\n",
    "    skews = []\n",
    "    for feat in idx:\n",
    "            mean = train_df.loc[:,feat].mean()\n",
    "            std = train_df.loc[:,feat].std()\n",
    "            kurt = train_df.loc[:,feat].kurtosis()\n",
    "            skew = train_df.loc[:,feat].skew()\n",
    "            means.append(mean)\n",
    "            stds.append(std)\n",
    "            kurts.append(kurt)\n",
    "            skews.append(skew)\n",
    "    var_info_df[\"means\"] = means\n",
    "    var_info_df[\"stds\"] = stds\n",
    "    var_info_df[\"kurts\"] = kurts\n",
    "    var_info_df[\"skews\"] = skews\n",
    "    \n",
    "#     var_info_df.plot.scatter(x = 'means', y = 'stds')\n",
    "#     var_info_df.plot.scatter(x = 'means', y = 'means')\n",
    "#     var_info_df.plot.scatter(x = 'means', y = 'kurts')\n",
    "#     var_info_df.plot.scatter(x = 'means', y = 'skews')\n",
    "#     var_info_df.to_csv(\"variable-means-etc.csv\", index=False)\n",
    "       \n",
    "    df_list = [train_df, test_df]\n",
    "    new_df_list = []\n",
    "    new_train_df = pd.DataFrame()\n",
    "    new_train_df['target'] = train_df['target']\n",
    "    new_test_df = pd.DataFrame()\n",
    "    new_df_list = [new_train_df, new_test_df]\n",
    "    for i in range(0, len(df_list)):        \n",
    "        for feat in idx:\n",
    "            mean = df_list[i].loc[:,feat].mean()\n",
    "            new_df_list[i][feat] = np.round(df_list[i][feat] , 3) \n",
    "            new_df_list[i][\"mm_\" + feat] = np.round(df_list[i][feat] - mean , 3) \n",
    "            new_df_list[i]['sq_log_'+ feat] = np.log(np.square(df_list[i][feat] - mean))            \n",
    "#             if mean > 7 or mean < -7:\n",
    "#                 df['r2_'+feat] = np.round(df[feat], 2)\n",
    "#                 df['r2mm_'+feat] = np.round(df[feat] - mean, 2) \n",
    "#                 df['r2mmsq_'+feat] = np.round(df[feat]*df[feat], 2)\n",
    "#                 print(mean)\n",
    "#             else:\n",
    "#                 df['r2_' +feat] = 0 #np.round(df[feat] - df[feat] , 2)    #zero\n",
    "#                 df['r2mm_'+feat] = 0 #np.round(df[feat] - df[feat] , 2)    #zero\n",
    "#                 df['r2mmsq_'+feat] = 0\n",
    "#                print(\"0\")\n",
    "#         df['sum'] = df[idx].sum(axis=1)  \n",
    "#         df['min'] = df[idx].min(axis=1)\n",
    "#         df['max'] = df[idx].max(axis=1)\n",
    "#         df['mean'] = df[idx].mean(axis=1)\n",
    "#         df['std'] = df[idx].std(axis=1)\n",
    "#         df['skew'] = df[idx].skew(axis=1)\n",
    "#         df['kurt'] = df[idx].kurtosis(axis=1)\n",
    "#         df['med'] = df[idx].median(axis=1)\n",
    "        \n",
    "#         #plot the data\n",
    "#         df.plot.scatter(x='mean', y='kurt')\n",
    "#         df.plot.scatter(x='mean', y='std')\n",
    "    \n",
    "    print('Train and test shape:',new_df_list[0].shape,new_df_list[1].shape)\n",
    "    #train_df.head(10)\n",
    "    return new_df_list[0], new_df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train_df, test_df):\n",
    "    features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "    target = train_df['target']\n",
    "    param = {\n",
    "            'num_leaves': 15, #was 10\n",
    "            'max_bin': 119,\n",
    "            'min_data_in_leaf': 11,\n",
    "            'learning_rate': 0.02,\n",
    "            'min_sum_hessian_in_leaf': 0.00245,\n",
    "            'bagging_fraction': 1.0, \n",
    "            'bagging_freq': 5, \n",
    "            'feature_fraction': 0.05,\n",
    "            'lambda_l1': 4.972,\n",
    "            'lambda_l2': 2.276,\n",
    "            'min_gain_to_split': 0.65,\n",
    "            'max_depth': 20, #was 14\n",
    "            'save_binary': True,\n",
    "            'seed': 1337,\n",
    "            'feature_fraction_seed': 1337,\n",
    "            'bagging_seed': 1337,\n",
    "            'drop_seed': 1337,\n",
    "            'data_random_seed': 1337,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': 1,\n",
    "            'metric': 'auc',\n",
    "            'is_unbalance': True,\n",
    "            'boost_from_average': True, #was false\n",
    "        }\n",
    "    num_round = 15000\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "    oof = np.zeros(len(train_df))\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 800)\n",
    "        oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "        predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['means-etc.csv', 'sample_submission.csv', 'test.csv', 'train.csv']\n",
      "Training dataset\n",
      "----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n",
      "Test dataset\n",
      "----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 201 entries, ID_code to var_199\n",
      "dtypes: float64(200), object(1)\n",
      "memory usage: 306.7+ MB\n",
      "Train and test shape: (200000, 601) (200000, 600)\n",
      "Fold 0\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[1000]\ttraining's auc: 0.917975\tvalid_1's auc: 0.885377\n",
      "[2000]\ttraining's auc: 0.940349\tvalid_1's auc: 0.896041\n",
      "[3000]\ttraining's auc: 0.953559\tvalid_1's auc: 0.898302\n",
      "[4000]\ttraining's auc: 0.963947\tvalid_1's auc: 0.898857\n",
      "Early stopping, best iteration is:\n",
      "[4032]\ttraining's auc: 0.964256\tvalid_1's auc: 0.898864\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 800 rounds.\n",
      "[1000]\ttraining's auc: 0.918089\tvalid_1's auc: 0.881268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2c2874505db7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ID_code\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID_code\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-0fe8159d4c34>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(train_df, test_df)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtrn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m800\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0moof\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))\n",
    "train=pd.read_csv(\"../input/train.csv\")\n",
    "print(\"Training dataset\")\n",
    "print(\"----------------\")\n",
    "train.info()\n",
    "\n",
    "test=pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Test dataset\")\n",
    "print(\"----------------\")\n",
    "test.info()\n",
    "\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "target = train['target']\n",
    "\n",
    "train_df, test_df = process_data(train, test)\n",
    "predictions = run_model(train_df, test_df)\n",
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
